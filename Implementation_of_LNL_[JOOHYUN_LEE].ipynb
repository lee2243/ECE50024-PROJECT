{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES AND PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.datasets import make_classification,load_breast_cancer,make_gaussian_quantiles\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION/LOADING AND PREPROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** Comment out except for one data loader or only run one of the following cell blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Linearly Separable 2D Dataset\n",
    "n = 10000 # number of samples\n",
    "dim = 2\n",
    "class_separation = 0.2 # distance between two classes \n",
    "p = 0.5\n",
    "r = 200 # range of data\n",
    "temp_label_neg = [] # label -1\n",
    "temp_label_pos = [] # label +1\n",
    "while len(temp_label_pos) < int(n*(1-p)):\n",
    "    x1 = random.randint(-r,r)\n",
    "    x2 = random.randint(-r,r)\n",
    "    if x1 - class_separation/2 * r >= x2:\n",
    "        temp_label_pos.append((x1,x2))\n",
    "while len(temp_label_neg) < int(n*p):\n",
    "    x1 = random.randint(-r,r)\n",
    "    x2 = random.randint(-r,r)\n",
    "    if x1 + class_separation/2 * r <= x2:\n",
    "        temp_label_neg.append((x1,x2)) \n",
    "\n",
    "X = np.vstack((temp_label_neg,temp_label_pos))\n",
    "label = np.hstack((np.zeros(len(temp_label_neg)),np.ones(len(temp_label_pos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Linearly Inseparable 2D Dataset\n",
    "n = 10000\n",
    "dim = 2\n",
    "X1, y1 = make_gaussian_quantiles(cov=2,\n",
    "                                 n_samples=int(n/2), n_features=dim,\n",
    "                                 n_classes=2)\n",
    "X2, y2 = make_gaussian_quantiles(mean=(5,5), cov=2,\n",
    "                                 n_samples=int(n/2), n_features=dim,\n",
    "                                 n_classes=2)\n",
    "\n",
    "\n",
    "X = np.concatenate((X1, X2))\n",
    "label = np.concatenate((y1,-y2+1))\n",
    "label = label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Linearly Inseparable High Dimensional Dataset\n",
    "n = 10000\n",
    "dim = 5\n",
    "X, label = make_classification(n_samples=n, n_features=dim, n_redundant=1, n_informative=dim-1,\n",
    "                                n_classes=2, n_clusters_per_class=dim-1, flip_y = 0,weights= (0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Heart Disease Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "hd= pd.read_csv(url, header=None)\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "hd.columns = column_names\n",
    "hd['target'] = hd['target'].replace([1, 2, 3, 4], 1)\n",
    "hd = hd.apply(pd.to_numeric, errors='coerce')\n",
    "hd = hd.dropna()\n",
    "hd = np.array(hd)\n",
    "label = hd[:,hd.shape[1]-1]\n",
    "X = hd[:,0:hd.shape[1]]\n",
    "dim = X.shape[1]\n",
    "n = len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Adult Dataset \n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "ad= pd.read_csv(url, header=None)\n",
    "column_names =['age', 'job', 'fnlwgt', 'edu', 'edunum', 'married', 'work', 'relationship', 'race', 'sex','capitalgain','capitalloss','hrsweek','country','Class']\n",
    "ad.columns = column_names\n",
    "ad['Class'] = ad['Class'].replace('<=50K', 0)\n",
    "ad['Class'] = ad['Class'].replace('>50K', 1)\n",
    "string_cols = ad.select_dtypes(include=['object']).columns\n",
    "num_cols = ad.select_dtypes(include=['int', 'float']).columns\n",
    "for col in string_cols:\n",
    "    le = LabelEncoder()\n",
    "    ad[col] = le.fit_transform(ad[col])\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_category = ohe.fit_transform(ad[['Class']])\n",
    "ad.drop('Class', axis=1, inplace=True)\n",
    "ad_encoded = pd.concat([ad, pd.DataFrame(encoded_category, columns=['category_0', 'category_1'])], axis=1)\n",
    "ad_encoded = np.array(ad_encoded)\n",
    "label = ad_encoded[:,ad_encoded.shape[1]-1]\n",
    "X = ad_encoded[:,0:ad_encoded.shape[1]-2]\n",
    "dim = X.shape[1]\n",
    "n = len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Ionosphere Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data'\n",
    "bn= pd.read_csv(url, header=None)\n",
    "column_names = [str(i) for i in range(1, 36)]\n",
    "bn.columns = column_names\n",
    "bn['35'] = bn['35'].replace('g', 1)\n",
    "bn['35'] = bn['35'].replace('b', 0)\n",
    "bn = np.array(bn)\n",
    "label = bn[:,bn.shape[1]-1]\n",
    "X = bn[:,0:bn.shape[1]-1]\n",
    "dim = X.shape[1]\n",
    "n = len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Credit Screening Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data'\n",
    "crx= pd.read_csv(url, header=None)\n",
    "column_names =[str(i) for i in range(1, 17)]\n",
    "crx.columns = column_names\n",
    "crx['16'] = crx['16'].replace('-', 0)\n",
    "crx['16'] = crx['16'].replace('+', 1)\n",
    "string_cols = crx.select_dtypes(include=['object']).columns\n",
    "num_cols = crx.select_dtypes(include=['int', 'float']).columns\n",
    "for col in string_cols:\n",
    "    le = LabelEncoder()\n",
    "    crx[col] = le.fit_transform(crx[col])\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_category = ohe.fit_transform(crx[['16']])\n",
    "crx.drop('16', axis=1, inplace=True)\n",
    "crx_encoded = pd.concat([crx, pd.DataFrame(encoded_category, columns=['category_0', 'category_1'])], axis=1)\n",
    "crx_encoded = np.array(crx_encoded)\n",
    "label = crx_encoded[:,crx_encoded.shape[1]-1]\n",
    "X = crx_encoded[:,0:crx_encoded.shape[1]-2]\n",
    "dim = X.shape[1]\n",
    "n = len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Banknote Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
    "bn= pd.read_csv(url, header=None)\n",
    "column_names =['wv0', 'wv1', 'wv2', 'wv3', 'Class']\n",
    "bn.columns = column_names\n",
    "bn = np.array(bn)\n",
    "label = bn[:,bn.shape[1]-1]\n",
    "X = bn[:,0:bn.shape[1]-1]\n",
    "dim = X.shape[1]\n",
    "n = len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI Breast Cancer Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "bc= pd.read_csv(url, header=None)\n",
    "column_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'Class']\n",
    "bc.columns = column_names\n",
    "bc['Class'] = bc['Class'].replace(2, 0)\n",
    "bc['Class'] = bc['Class'].replace(4, 1)\n",
    "bc = bc.apply(pd.to_numeric, errors='coerce')\n",
    "bc = bc.dropna()\n",
    "bc = np.array(bc)\n",
    "bc1 = np.delete(bc, 0, axis=1)\n",
    "label = bc[:,bc.shape[1]-1]\n",
    "X = bc[:,0:bc.shape[1]]\n",
    "dim = X.shape[1]\n",
    "n = len(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---$\\uparrow$---END of Dataset Selection---$\\uparrow$---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE NOISY TRAIN/TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Rate\n",
    "rho_neg = 0.4\n",
    "rho_pos = 0.4\n",
    "\n",
    "data_neg = []\n",
    "data_pos = []\n",
    "for d in np.hstack((X, label.reshape(-1,1))):\n",
    "    if d[dim] == 0:\n",
    "        data_neg.append(np.hstack((d[:dim], -1)))\n",
    "    else:\n",
    "        data_pos.append(d)        \n",
    "data_neg = np.array(data_neg)\n",
    "data_pos = np.array(data_pos)\n",
    "\n",
    "# Create data with no label noise and map the first two column to third column\n",
    "data_clean = np.vstack((data_neg,data_pos))\n",
    "map = {}\n",
    "for D in data_clean:\n",
    "    key = tuple(D[:dim])\n",
    "    value = D[dim]\n",
    "    map[key] = value\n",
    "    \n",
    "\n",
    "\n",
    "noise_neg = np.random.choice([0, 1], size=len(data_neg), p=[(1-rho_neg), rho_neg])\n",
    "data_neg[:,dim][noise_neg == 1] = 1\n",
    "noise_pos = np.random.choice([0, 1], size=len(data_pos), p=[(1-rho_pos), rho_pos])\n",
    "data_pos[:,dim][noise_pos == 1] = -1\n",
    "\n",
    "data_noisy = np.vstack((data_neg, data_pos))\n",
    "\n",
    "data_train, data_test, clean_train, clean_test  = train_test_split(data_noisy, data_clean,train_size=0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline method\n",
    "dlf = svm.SVC(kernel=\"rbf\")\n",
    "dlf.fit(data_train[:,0:dim], data_train[:,dim])\n",
    "\n",
    "pred_base = dlf.predict(data_test[:,0:dim])\n",
    "\n",
    "acc = accuracy_score(clean_test[:,dim], pred_base)\n",
    "print(\"Accuracy: {:0.4f}\".format(acc))\n",
    "\n",
    "# Project data to two dimension(only for synthetic datasets)\n",
    "recon_base= {(D[0],D[1]):int(label) for label, D in zip(pred_base,data_test[:,0:dim])}\n",
    "recon_array_base = np.array([(D[0], D[1], value) for D, value in recon_base.items()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_loss(y_true, y_pred, rho_pos, rho_neg):\n",
    "    original_loss_pos = np.maximum(0, 1 - y_true * y_pred) # l(t,y)\n",
    "    original_loss_neg = np.maximum(0, 1 - (-y_true) * y_pred) # l(t,-y)\n",
    "\n",
    "    # Compute modified loss\n",
    "    mod_neg = ((1 - rho_pos) * original_loss_neg - rho_neg * original_loss_pos)\n",
    "    mod_pos = ((1 - rho_neg) * original_loss_pos - rho_pos * original_loss_neg)\n",
    "\n",
    "    modified_loss = (mod_neg + mod_pos)/(1 - rho_pos - rho_neg)\n",
    "    return  modified_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implmentation\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(data_train[:,0:dim], data_train[:,dim])\n",
    "ini_pred = clf.predict(data_train[:,0:dim])\n",
    "\n",
    "clf.fit(data_train[:,0:dim], data_train[:,dim], sample_weight = \n",
    "        ((np.array(([modified_loss(true_label, pred_label, rho_pos, rho_neg) for true_label, pred_label in zip(data_train[:,dim], ini_pred)])))))\n",
    "\n",
    "y_pred = clf.predict(data_test[:,0:dim])\n",
    "\n",
    "accuracy = accuracy_score(clean_test[:,dim], y_pred)\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy))\n",
    "\n",
    "# Project data to two dimension (only for synthetic datasets)\n",
    "recon = {(D[0],D[1]):int(label) for label, D in zip(y_pred, data_test[:,0:dim])}\n",
    "recon_array = np.array([(key[0], key[1], value) for key, value in recon.items()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT (ONLY FOR SYNTHETIC DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for synthetic datasets\n",
    "fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2,2,figsize=(12,12))\n",
    "fig.suptitle('$\\u03C1_-$$_1$ = {:0.2f} '.format(rho_neg) + ' $\\u03C1_+$$_1$ = {:0.2f}'.format(rho_pos), fontsize=24)\n",
    "ax1.scatter(clean_test[:,0], clean_test[:,1], c=np.where(clean_test[:,dim]==1, 'red', 'blue'), marker='.')\n",
    "ax2.scatter(data_test[:,0], data_test[:,1], c=np.where(data_test[:,dim]==1, 'red', 'blue'), marker='.')\n",
    "ax3.scatter(recon_array_base[:,0], recon_array_base[:,1], c=np.where(recon_array_base[:,2]==1, 'red', 'blue'), marker='.')\n",
    "ax4.scatter(recon_array[:,0], recon_array[:,1], c=np.where(recon_array[:,2]==1, 'red', 'blue'), marker='.')\n",
    "ax1.set_title('(a)', fontsize=18)\n",
    "ax2.set_title('(b)', fontsize=18)\n",
    "ax3.set_title('(c) Accuracy: {:0.4f}'.format(acc), fontsize=18)\n",
    "ax4.set_title('(d) Accuracy: {:0.4f}'.format(accuracy), fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
